services:
  zookeeper:
    build:
      context: ./infra/zookeeper
      dockerfile: Dockerfile
    image: zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_JMX_PORT: 9998
      KAFKA_JMX_HOSTNAME: zookeeper
      KAFKA_OPTS: "-javaagent:/usr/share/jmx_prometheus_javaagent.jar=7072:/etc/jmx-exporter/config.yml"
    ports:
      - "2181:2181"
      - "7072:7072"  # JMX Exporter metrics
      - "9998:9998"  # JMX port
    networks:
      - ft_Transc
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  
  kafka:
    build:
      context: ./infra/kafka
      dockerfile: Dockerfile
    image: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "7071:7071"  # JMX Exporter metrics
      - "9999:9999"  # JMX port
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: kafka
      KAFKA_OPTS: "-javaagent:/usr/share/jmx_prometheus_javaagent.jar=7071:/etc/jmx-exporter/config.yml"
    depends_on:
      - zookeeper
    networks:
      - ft_Transc
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # kafka-ui:
  #   build:
  #     context: ./infra/kafka-ui
  #     dockerfile: Dockerfile
  #   image: kafka-ui
  #   container_name: kafka-ui
  #   ports:
  #     - "3022:3022"
  #   environment:
  #     - KAFKA_CLUSTERS_0_NAME=local
  #     - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
  #   depends_on:
  #     - kafka
  #   networks:
  #     - ft_Transc
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

  chat-service:
    build:
      context: ./app/backend/services/chat
      dockerfile: Dockerfile
    image: chat-service
    container_name: chat-service
    ports:
      - "3003:3003"
    environment:
      - KAFKA_BROKER=kafka:9092
    depends_on:
      - kafka
    networks:
      - ft_Transc
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  api-gateway:
    build:
      context: ./app/backend/api_gateway
      dockerfile: dockerfile
    image: api-gateway
    container_name: api-gateway
    ports:
      - "8080:8080"
    environment:
      - VAULT_ADDR=${VAULT_ADDR:-http://vault:8200}
      - VAULT_TOKEN=${VAULT_TOKEN:-dev-root-token}
    networks:
      - ft_Transc
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  game-service:
    build:
      context: ./app/backend/services/game
      dockerfile: dockerfile
    image: game-service
    container_name: game-service
    ports:
      - "3005:3005"
    environment:
      - KAFKA_BROKER=kafka:9092
    depends_on:
      - kafka
    networks:
      - ft_Transc
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        
  notification-service:
    build:
      context: ./app/backend/services/notification
      dockerfile: dockerfile
    image: notification-service
    container_name: notification-service
    ports:
      - "3006:3006"
    environment:
      - KAFKA_BROKER=kafka:9092
    depends_on:
      - kafka
    networks:
      - ft_Transc
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"


  prometheus:
    build:
      context: ./infra/monitoring/prometheus
      dockerfile: Dockerfile
    image: prometheus
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - prometheus-data:/prometheus
      - ./infra/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./infra/monitoring/prometheus/alert.rules.yml:/etc/prometheus/alert.rules.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    networks:
      - ft_Transc
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  alertmanager:
    build:
      context: ./infra/monitoring/alertmanager
      dockerfile: Dockerfile
    image: alertmanager
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - alertmanager-data:/alertmanager
      - ./infra/monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    networks:
      - ft_Transc
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  node-exporter:
    build:
      context: ./infra/monitoring/node-exporter
      dockerfile: Dockerfile
    image: node-exporter
    container_name: node-exporter
    ports:
      - "9101:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - ft_Transc
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  grafana:
    build:
      context: ./infra/monitoring/grafana
      dockerfile: Dockerfile
    image: grafana
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./infra/monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./infra/monitoring/grafana/dashboards:/var/lib/grafana/dashboards
      - ./infra/monitoring/grafana/grafana.ini:/etc/grafana/grafana.ini
    environment:
      - GF_SECURITY_ADMIN_USER=hidriouc
      - GF_SECURITY_ADMIN_PASSWORD=hidriouc
      - GF_SECURITY_SECRET_KEY=SW2YcwTIb9zpOOhoPsMm
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
    depends_on:
      - prometheus
      - alertmanager
    networks:
      - ft_Transc
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================
  # ELK Stack for Log Management
  # ============================================
  elasticsearch:
    build:
      context: ./infra/log-management/elasticsearch
      dockerfile: Dockerfile
    image: elasticsearch
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD:-changeme}
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - ft_Transc
    restart: unless-stopped

  logstash:
    build:
      context: ./infra/log-management/logstash
      dockerfile: Dockerfile
    image: logstash
    container_name: logstash
    ports:
      - "5044:5044"
    volumes:
      - ./infra/log-management/logstash/pipeline:/usr/share/logstash/pipeline:ro
    environment:
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD:-changeme}
    depends_on:
      - elasticsearch
    networks:
      - ft_Transc
    restart: unless-stopped

  kibana:
    build:
      context: ./infra/log-management/kibana
      dockerfile: Dockerfile
    image: kibana
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD:-changeme}
      - KIBANA_PASSWORD=${KIBANA_PASSWORD:-changeme}
    depends_on:
      - elasticsearch
    networks:
      - ft_Transc
    restart: unless-stopped

  filebeat:
    build:
      context: ./infra/log-management/filebeat
      dockerfile: Dockerfile
    image: filebeat
    container_name: filebeat
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    environment:
      - LOGSTASH_HOSTS=logstash:5044
    depends_on:
      - elasticsearch
      - logstash
    networks:
      - ft_Transc
    restart: unless-stopped

  frontend:
    build:
      context: .
      dockerfile: ./infra/nginx/Dockerfile.frontend
    image: frontend
    container_name: frontend
    ports:
      - "0.0.0.0:80:80"
      - "0.0.0.0:443:443"
    depends_on:
      - api-gateway
      - tictac-game
    networks:
      - ft_Transc
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 3s
      start_period: 5s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  frontend-dev:
    build:
      context: ./app/frontend
      dockerfile: Dockerfile.dev
    image: frontend-dev
    container_name: frontend-dev
    ports:
      - "5173:5173"
    volumes:
      - ./app/frontend:/app
      - /app/node_modules
    networks:
      - ft_Transc
    profiles:
      - development
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  tictac-game:
    build:
      context: ./app/backend/services/tictac
      dockerfile: Dockerfile
    image: tictac-game
    container_name: tictac-game
    ports:
      - "0.0.0.0:3030:3030"
    environment:
      - PORT=3030
      - HOST=0.0.0.0
      - NODE_ENV=production
      - DATABASE_PATH=/app/data/tictac.db
      - RATE_LIMIT_MAX=100
      - RATE_LIMIT_TIMEWINDOW=60000
      - MATCHMAKING_TIMEOUT=60000
      - SKILL_RANGE=100
      - CORS_ORIGIN=http://localhost:5173,http://localhost:8888,http://10.32.138.11:5173,http://10.32.138.11:8888
    volumes:
      - tictac-data:/app/data
    networks:
      - ft_Transc
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3030/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      start_period: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  user_auth:
    build:
      context: ./app/backend/services/userAuth
      dockerfile: Dockerfile
    image: user_auth
    container_name: user_auth
    volumes:
      - ./backend/services/userauth/db:/app/db
    ports:
      - "3004:3004"
    environment:
      NODE_ENV: production
      JWT_SECRET: ${JWT_SECRET:-breakingPong_123!@}
      JWT_REFRESH: ${JWT_REFRESH:-breakingPong_Refresh_123!@}
      COOKIE_SECRET: ${COOKIE_SECRET:-superSecretCookieKey!@}
    networks:
      - ft_Transc
    depends_on:
      - kafka
      - zookeeper
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  vault:
    build:
      context: ./infra/vault
      dockerfile: Dockerfile
    image: vault
    container_name: vault
    ports:
      - "8200:8200"
    environment:
      - VAULT_ADDR=http://0.0.0.0:8200
      - VAULT_API_ADDR=http://vault:8200
      - VAULT_DEV_ROOT_TOKEN_ID=dev-root-token
      - VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200
    volumes:
      - vault-data:/vault/data
      - vault-logs:/vault/logs
      - ./infra/vault/scripts:/vault/scripts:ro
    networks:
      - ft_Transc
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "vault", "status"]
      interval: 10s
      timeout: 3s
      start_period: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  ft_Transc:
    driver: bridge

volumes:
  prometheus-data:
  alertmanager-data:
  grafana-data:
  elasticsearch-data:
  tictac-data:
  vault-data:
  vault-logs:
  vault-config:
